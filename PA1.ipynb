{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "from os import listdir\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./aligned/\"):\n",
    "    \"\"\" Load all PNG images stored in your data directory into a list of NumPy\n",
    "        arrays.\n",
    "\n",
    "    Args:\n",
    "    data_dir: The relative directory path to the CompCar image directory.\n",
    "    Returns:\n",
    "        images: A dictionary with keys as car types and a list containing images associated with each key.\n",
    "        cnt: A dictionary that stores the # of images in each car type\n",
    "    \"\"\"\n",
    "    images = defaultdict(list)\n",
    "\n",
    "    # Get the list of car type directory:\n",
    "    for e in listdir(data_dir):\n",
    "        # excluding any non-directory files\n",
    "        if not os.path.isdir(os.path.join(data_dir, e)):\n",
    "            continue\n",
    "        # Get the list of image file names\n",
    "        all_files = listdir(os.path.join(data_dir, e))\n",
    "\n",
    "        for file in all_files:\n",
    "            # Load only image files as PIL images and convert to NumPy arrays\n",
    "            if '.jpg' in file:\n",
    "                img = Image.open(os.path.join(data_dir, e, file))\n",
    "                images[e].append(np.array(img))\n",
    "\n",
    "    print(\"Car types: {} \\n\".format(list(images.keys())))\n",
    "\n",
    "    cnt = defaultdict(int)\n",
    "    for e in images.keys():\n",
    "        print(\"{}: {} # of images\".format(e, len(images[e])))\n",
    "        cnt[e] = len(images[e])\n",
    "    return images, cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in all the img from all set and return a list of sets of mutually exclusive images and its labels.\n",
    "def k_fold(imgs, k):\n",
    "    res = []\n",
    "    for _ in range(k):\n",
    "        res.append(defaultdict(list))\n",
    "    for key in imgs.keys():\n",
    "        for i, entry in enumerate(imgs[key]):\n",
    "            res[i%k][key].append(entry)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, n_components):\n",
    "\n",
    "    \"\"\"Args:\n",
    "        X: has shape Mxd where M is the number of images and d is the dimension of each image\n",
    "        n_components: The number of components you want to project your image onto. \n",
    "    \n",
    "    Returns:\n",
    "        projected: projected data of shape M x n_components\n",
    "        mean_image: mean of all images\n",
    "        top_sqrt_eigen_values: singular values\n",
    "        top_eigen_vectors: eigenvectors \n",
    "    \"\"\"\n",
    "    mean_image = np.average(X, axis = 0)\n",
    "\n",
    "    msd = X - mean_image # M x d\n",
    "\n",
    "    smart_cov_matrix = np.matmul(msd, msd.T)\n",
    "    eigen_values, smart_eigen_vectors = np.linalg.eig(smart_cov_matrix)\n",
    "\n",
    "    idx = eigen_values.argsort()[::-1]   \n",
    "    eigen_values = eigen_values[idx]\n",
    "    smart_eigen_vectors = smart_eigen_vectors[:,idx]\n",
    "\n",
    "    eigen_vectors = (np.matmul(msd.T, smart_eigen_vectors)).T # M x d\n",
    "\n",
    "    row_norm = np.sum(np.abs(eigen_vectors)**2,axis=-1)**(1./2) # M\n",
    "\n",
    "    normalized_eigen_vectors = eigen_vectors/(row_norm.reshape(-1, 1)) # M x d\n",
    "\n",
    "    top_eigen_vectors = normalized_eigen_vectors[:n_components].T\n",
    "    top_sqrt_eigen_values = np.sqrt(eigen_values[:n_components])\n",
    "\n",
    "    projected = np.matmul(msd, top_eigen_vectors)/top_sqrt_eigen_values\n",
    "\n",
    "    return projected, mean_image, top_sqrt_eigen_values, top_eigen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car types: ['Pickup', 'Sedan', 'Minivan', 'Convertible'] \n",
      "\n",
      "Pickup: 150 # of images\n",
      "Sedan: 150 # of images\n",
      "Minivan: 148 # of images\n",
      "Convertible: 149 # of images\n"
     ]
    }
   ],
   "source": [
    "img, cnt = load_data()\n",
    "folds = k_fold(img, 10)\n",
    "test, validation = folds[0], folds[1]\n",
    "train = defaultdict(list)\n",
    "for trainLoaderIter in range(2, 10):\n",
    "    for key in folds[trainLoaderIter].keys():\n",
    "        train[key].extend(folds[trainLoaderIter][key])\n",
    "totalTrainingAmount = 0\n",
    "for key in train.keys():\n",
    "    totalTrainingAmount += len(train[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n"
     ]
    }
   ],
   "source": [
    "print(totalTrainingAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newTrainingConvertable = train['Convertible']\n",
    "X = []\n",
    "y= []\n",
    "\n",
    "for i in range(len(train['Convertible'])):\n",
    "    X.append(train['Convertible'][i].reshape((-1)))\n",
    "    y.append(0)\n",
    "for i in range(len(train['Minivan'])):\n",
    "    X.append(train['Minivan'][i].reshape((-1)))\n",
    "    y.append(1)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(1, len(y)).T\n",
    "#print(X.shape, y.shape)\n",
    "#from sklearn.decomposition import PCA as skPCA\n",
    "\n",
    "#pca = skPCA(n_components=)\n",
    "#X = pca.fit_transform(X)\n",
    "#print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected, mean_image, top_sqrt_eigen_values, top_eigen_vectors = PCA(X, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_regression:\n",
    "    def __init__(self, dimension, lr):\n",
    "        self.lr = lr\n",
    "        self.w = np.zeros(dimension)\n",
    "        \n",
    "    def sigmoid(self, X):\n",
    "        return 1.0 / (1.0 + np.exp(-X))\n",
    "    \n",
    "    def caculateGradient(self, X, yTrue):\n",
    "        grad = X * (yTrue.reshape(-1) - self.sigmoid(X@self.w)).reshape((-1, 1))\n",
    "        return np.sum(grad, axis=0) * (1/len(X))\n",
    "    \n",
    "    def updateWeight(self, X, yTrue):\n",
    "        self.w = self.w + self.lr * self.caculateGradient(X, yTrue)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X@self.w.T)\n",
    "    \n",
    "    def score(self, X, yTrue):\n",
    "        yCalculated = self.predict(X)\n",
    "        correct = 0\n",
    "        for i in range(len(X)):\n",
    "            print(yCalculated[i], yTrue[i])\n",
    "            if yCalculated[i] == yTrue[i]:\n",
    "                correct += 1\n",
    "        return correct / len(yCalculated)\n",
    "    \n",
    "    def logLikelihood(self, X, yTrue):\n",
    "        LL = 0.0\n",
    "        for t in range(X.shape[0]):\n",
    "            LL += yTrue[t] * np.log(self.sigmoid(self.w.T@X[t])) + (1-yTrue[t]) * np.log(1-self.sigmoid(self.w.T@X[t]))\n",
    "        return LL\n",
    "    \n",
    "    def fit(self, X, y, epoch):\n",
    "        log = []\n",
    "        for _ in range(epoch):\n",
    "            self.updateWeight(X, y)\n",
    "            log.append(self.logLikelihood(X, y))\n",
    "        return log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = Logistic_regression(projected.shape[1], 0.5)\n",
    "Loss = LR.fit(projected, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4997972855625645 [0]\n",
      "0.49996575731951054 [0]\n",
      "0.49995824394563476 [0]\n",
      "0.49973735795531254 [0]\n",
      "0.4998829436291287 [0]\n",
      "0.500078536038669 [0]\n",
      "0.4998748734941859 [0]\n",
      "0.4999995442203051 [0]\n",
      "0.4998835564076846 [0]\n",
      "0.4998676484436798 [0]\n",
      "0.4998152096722775 [0]\n",
      "0.4996207429175877 [0]\n",
      "0.5001316334449035 [0]\n",
      "0.5000682938886598 [0]\n",
      "0.49990008181360596 [0]\n",
      "0.4997281237188411 [0]\n",
      "0.49967071857156325 [0]\n",
      "0.49995753859972314 [0]\n",
      "0.5001498549009162 [0]\n",
      "0.49971413576472057 [0]\n",
      "0.4997425683235039 [0]\n",
      "0.49990091276201865 [0]\n",
      "0.4997831315609135 [0]\n",
      "0.4998048641815359 [0]\n",
      "0.4997542317447117 [0]\n",
      "0.4999097975373625 [0]\n",
      "0.5002028996631172 [0]\n",
      "0.499941588347215 [0]\n",
      "0.4998340318308769 [0]\n",
      "0.4999022855939719 [0]\n",
      "0.49993581310902385 [0]\n",
      "0.49983326516858556 [0]\n",
      "0.4998324775930368 [0]\n",
      "0.49985617425817447 [0]\n",
      "0.4996838487930408 [0]\n",
      "0.4998985222605544 [0]\n",
      "0.500152961632155 [0]\n",
      "0.4998004968373589 [0]\n",
      "0.499995636366424 [0]\n",
      "0.5000433173255211 [0]\n",
      "0.4999760268789467 [0]\n",
      "0.4995471083911738 [0]\n",
      "0.5000338646651722 [0]\n",
      "0.4998548521026598 [0]\n",
      "0.499810163772994 [0]\n",
      "0.4997703334430294 [0]\n",
      "0.4998613311418079 [0]\n",
      "0.49992633042693246 [0]\n",
      "0.49971954524878076 [0]\n",
      "0.4999694620418648 [0]\n",
      "0.49976516646323843 [0]\n",
      "0.4998513953869168 [0]\n",
      "0.4997661732348258 [0]\n",
      "0.5001078690485647 [0]\n",
      "0.49993011104295354 [0]\n",
      "0.4998390022139534 [0]\n",
      "0.49988026804058755 [0]\n",
      "0.49975260122504134 [0]\n",
      "0.499829951206326 [0]\n",
      "0.5000140397887541 [0]\n",
      "0.4998472731786398 [0]\n",
      "0.49996721747600337 [0]\n",
      "0.49984197307401673 [0]\n",
      "0.4998542789963318 [0]\n",
      "0.4998045015357351 [0]\n",
      "0.4999671046770163 [0]\n",
      "0.49980237369403335 [0]\n",
      "0.49968476542366136 [0]\n",
      "0.4999569441659817 [0]\n",
      "0.5001150057827648 [0]\n",
      "0.4999559150245843 [0]\n",
      "0.4997481165620323 [0]\n",
      "0.49994060807514734 [0]\n",
      "0.49992501023087366 [0]\n",
      "0.4997538035112884 [0]\n",
      "0.4997336018679852 [0]\n",
      "0.4999647596601746 [0]\n",
      "0.4998106382896659 [0]\n",
      "0.49994284579705783 [0]\n",
      "0.49972521247857227 [0]\n",
      "0.499531412420765 [0]\n",
      "0.5000070839469903 [0]\n",
      "0.49970125377726515 [0]\n",
      "0.49974826746154116 [0]\n",
      "0.4997303077779466 [0]\n",
      "0.49975832989685337 [0]\n",
      "0.5001127873260925 [0]\n",
      "0.49987037025670067 [0]\n",
      "0.4998313321747029 [0]\n",
      "0.4998978827765991 [0]\n",
      "0.4998538754307708 [0]\n",
      "0.49978870268883513 [0]\n",
      "0.4997051460387352 [0]\n",
      "0.49990552894738866 [0]\n",
      "0.49990883350539833 [0]\n",
      "0.49958947548007004 [0]\n",
      "0.4999202609710768 [0]\n",
      "0.4998124208072959 [0]\n",
      "0.49972511367203354 [0]\n",
      "0.49992359274712156 [0]\n",
      "0.4997621697458828 [0]\n",
      "0.5000139970825445 [0]\n",
      "0.4999570235341133 [0]\n",
      "0.4999695267552273 [0]\n",
      "0.4999387887766462 [0]\n",
      "0.4999768817515955 [0]\n",
      "0.4997990162131334 [0]\n",
      "0.49970082295477264 [0]\n",
      "0.4997889406197067 [0]\n",
      "0.4997501747793773 [0]\n",
      "0.5000446806780304 [0]\n",
      "0.4998452453584418 [0]\n",
      "0.49962177377843003 [0]\n",
      "0.49981776597223315 [0]\n",
      "0.5000175433191911 [0]\n",
      "0.4999658591958209 [0]\n",
      "0.49973443644037285 [0]\n",
      "0.4998078868502902 [0]\n",
      "0.4997532762448492 [0]\n",
      "0.5001048357953644 [1]\n",
      "0.5001536731434424 [1]\n",
      "0.5002391189615172 [1]\n",
      "0.5002425538638738 [1]\n",
      "0.5000402847828442 [1]\n",
      "0.5001975573284975 [1]\n",
      "0.5000748514995896 [1]\n",
      "0.5003909196072654 [1]\n",
      "0.5001938548533525 [1]\n",
      "0.5001684990500074 [1]\n",
      "0.5001479432604422 [1]\n",
      "0.5001349265129441 [1]\n",
      "0.5001768125866871 [1]\n",
      "0.4997972170645001 [1]\n",
      "0.5003766039955262 [1]\n",
      "0.5001453064933054 [1]\n",
      "0.5002954764542724 [1]\n",
      "0.5000292693949405 [1]\n",
      "0.5000895856084377 [1]\n",
      "0.5001795485637571 [1]\n",
      "0.5003812978169313 [1]\n",
      "0.5002917977685787 [1]\n",
      "0.5001864557264949 [1]\n",
      "0.49992598717664477 [1]\n",
      "0.5000064433475739 [1]\n",
      "0.4999821275685718 [1]\n",
      "0.4999983174783976 [1]\n",
      "0.4999862281863801 [1]\n",
      "0.49998900886747866 [1]\n",
      "0.5003912382519758 [1]\n",
      "0.5001209523696839 [1]\n",
      "0.5001347190103329 [1]\n",
      "0.5001975151704904 [1]\n",
      "0.5002257782299044 [1]\n",
      "0.5002427734357076 [1]\n",
      "0.5001326413951646 [1]\n",
      "0.5003995822582856 [1]\n",
      "0.5001533556953848 [1]\n",
      "0.500053048306367 [1]\n",
      "0.5001325527609577 [1]\n",
      "0.5001553337651218 [1]\n",
      "0.5001732588624943 [1]\n",
      "0.5000650939499094 [1]\n",
      "0.5000722923322752 [1]\n",
      "0.49992580153691213 [1]\n",
      "0.500135785937386 [1]\n",
      "0.5000033153358632 [1]\n",
      "0.500303089142647 [1]\n",
      "0.5006186398536523 [1]\n",
      "0.500166380952701 [1]\n",
      "0.5002971730079041 [1]\n",
      "0.5001444665746962 [1]\n",
      "0.5001486015439642 [1]\n",
      "0.5000978584460021 [1]\n",
      "0.499992618148998 [1]\n",
      "0.5002484418967409 [1]\n",
      "0.500049956589211 [1]\n",
      "0.5000222280407196 [1]\n",
      "0.5000087720047861 [1]\n",
      "0.4999425958138136 [1]\n",
      "0.5000078394449492 [1]\n",
      "0.500143750864494 [1]\n",
      "0.5001305434703486 [1]\n",
      "0.500416329834134 [1]\n",
      "0.5000497107667903 [1]\n",
      "0.5002231760302382 [1]\n",
      "0.5001131312150638 [1]\n",
      "0.5000218504500403 [1]\n",
      "0.5003291414082199 [1]\n",
      "0.5002030637003119 [1]\n",
      "0.5003602900901892 [1]\n",
      "0.49996890655307963 [1]\n",
      "0.5002937781667349 [1]\n",
      "0.49983936641278814 [1]\n",
      "0.5001512955204458 [1]\n",
      "0.500117084522064 [1]\n",
      "0.5000270449185579 [1]\n",
      "0.500278762509931 [1]\n",
      "0.4998336242553465 [1]\n",
      "0.5002690573851706 [1]\n",
      "0.5001501474441482 [1]\n",
      "0.5000885698193586 [1]\n",
      "0.5001272658323729 [1]\n",
      "0.5001085068543357 [1]\n",
      "0.5002165092714863 [1]\n",
      "0.4999663157246614 [1]\n",
      "0.500090162112412 [1]\n",
      "0.5001216610226508 [1]\n",
      "0.5000790457002311 [1]\n",
      "0.5000707821988369 [1]\n",
      "0.5002663852150468 [1]\n",
      "0.5002935134451874 [1]\n",
      "0.5002617996823564 [1]\n",
      "0.500102937212061 [1]\n",
      "0.5002644952357287 [1]\n",
      "0.5000407450930393 [1]\n",
      "0.4999928545187478 [1]\n",
      "0.5002968174259902 [1]\n",
      "0.5001821999255675 [1]\n",
      "0.5002350150888935 [1]\n",
      "0.5000945311982276 [1]\n",
      "0.49994247495481176 [1]\n",
      "0.4999576373968719 [1]\n",
      "0.4999469284416325 [1]\n",
      "0.5002143509691053 [1]\n",
      "0.49997788461265197 [1]\n",
      "0.5001573162643473 [1]\n",
      "0.5001346337324573 [1]\n",
      "0.5001948411102958 [1]\n",
      "0.5001698196505338 [1]\n",
      "0.5001358798023098 [1]\n",
      "0.5003305790718997 [1]\n",
      "0.5001497866634156 [1]\n",
      "0.5001901982062068 [1]\n",
      "0.5000415292150583 [1]\n",
      "0.5000723353219843 [1]\n",
      "0.5000060325555966 [1]\n",
      "0.5001211622727968 [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(projected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log likelihood')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Loss)\n",
    "plt.title(\"Log likelihood vs Steps (Training)\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Log likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ShawnXu/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8059071729957806"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg = LogisticRegression().fit(projected, y.reshape((-1)))\n",
    "reg.score(projected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#(a) Implement Logistic Regression via Gradient Descent. (5 points)\n",
    "#Now, without using any high-level machine learning libraries, implement logistic regression. Here, you’ll be using batch gradient descent, and will only need one logistic output unit. (Think about why we only need one if we’re classifying two classes?) The most points will be given for clean, well-documented code.\n",
    "def gradient_descent(X, y, lr=0.05, epoch=300):\n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    X -> feature -> m * d\n",
    "    y -> label -> m\n",
    "    lr -> learning rate\n",
    "    epoch -> epoch\n",
    "    \n",
    "    weights <-\n",
    "    mse     <-\n",
    "    '''\n",
    "    \n",
    "    weight = np.zeros((X.shape[1], 1))\n",
    "    N = len(X) # number of samples\n",
    "    log = []\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        errorSum = np.zeros((X.shape[1], 1))\n",
    "        #biasIncludedX = np.append(X, np.ones((X.shape[0], 1)), 1)\n",
    "        calculatedTarget = X@weight\n",
    "        #print(calculatedTarget, y)\n",
    "        diffs = y - calculatedTarget\n",
    "        #print(diffs.shape, y.shape, calculatedTarget.shape)\n",
    "        for i, diff in enumerate(diffs):\n",
    "            #print(diff.shape, errorSum.shape, X[i].shape)\n",
    "            #print(diff[0])\n",
    "            errorSum += diff[0] * X[i].reshape((-1, 1))\n",
    "        weight += errorSum * lr * (2/N)\n",
    "        #print(weight)\n",
    "        log.append(sum(diffs**2)[0])\n",
    "\n",
    "    return weight, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-049695596806>:32: RuntimeWarning: overflow encountered in square\n",
      "  log.append(sum(diffs**2)[0])\n",
      "<ipython-input-41-049695596806>:29: RuntimeWarning: overflow encountered in multiply\n",
      "  errorSum += diff[0] * X[i].reshape((-1, 1))\n",
      "<ipython-input-41-049695596806>:29: RuntimeWarning: overflow encountered in add\n",
      "  errorSum += diff[0] * X[i].reshape((-1, 1))\n",
      "<ipython-input-41-049695596806>:22: RuntimeWarning: invalid value encountered in matmul\n",
      "  calculatedTarget = X@weight\n"
     ]
    }
   ],
   "source": [
    "w, l = gradient_descent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.0, 3.104076254465395e+17, 1.673244493858922e+33, 9.020297129799019e+48, 4.8627539270974253e+64, 2.6214630644143286e+80, 1.4132050893618976e+96, 7.618450367312572e+111, 4.107032053317335e+127, 2.2140607963199377e+143, 1.1935785126978462e+159, 6.434464981006501e+174, 3.4687571157943585e+190, 1.8699730224488486e+206, 1.0080841603940608e+222, 5.434483076694745e+237, 2.929676655105549e+253, 1.5793600205101066e+269, 8.514175344363435e+284, 4.589908624580285e+300, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(X, mean_image, n_components):\n",
    "    msd = X - mean_image # M x d\n",
    "\n",
    "    smart_cov_matrix = np.matmul(msd, msd.T)\n",
    "    eigen_values, smart_eigen_vectors = np.linalg.eig(smart_cov_matrix)\n",
    "\n",
    "    idx = eigen_values.argsort()[::-1]   \n",
    "    eigen_values = eigen_values[idx]\n",
    "    smart_eigen_vectors = smart_eigen_vectors[:,idx]\n",
    "\n",
    "    eigen_vectors = (np.matmul(msd.T, smart_eigen_vectors)).T # M x d\n",
    "\n",
    "    row_norm = np.sum(np.abs(eigen_vectors)**2,axis=-1)**(1./2) # M\n",
    "\n",
    "    normalized_eigen_vectors = eigen_vectors/(row_norm.reshape(-1, 1)) # M x d\n",
    "\n",
    "    top_eigen_vectors = normalized_eigen_vectors[:n_components].T\n",
    "    top_sqrt_eigen_values = np.sqrt(eigen_values[:n_components])\n",
    "\n",
    "    projected = np.matmul(msd, top_eigen_vectors)/top_sqrt_eigen_values\n",
    "\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9513201441478435"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.09062380e+00]\n",
      " [ 1.13370466e+00]\n",
      " [ 9.96141150e-01]\n",
      " [ 9.79065039e-01]\n",
      " [ 8.32071519e-01]\n",
      " [ 1.00414370e+00]\n",
      " [ 1.03011653e+00]\n",
      " [ 9.09847423e-01]\n",
      " [ 9.47712967e-01]\n",
      " [ 8.89817480e-01]\n",
      " [ 1.01802904e+00]\n",
      " [ 6.35254183e-01]\n",
      " [ 1.02264444e+00]\n",
      " [ 9.29018337e-01]\n",
      " [ 1.14174318e+00]\n",
      " [ 8.92076144e-01]\n",
      " [ 1.00485116e+00]\n",
      " [ 9.72286533e-01]\n",
      " [ 9.42922905e-01]\n",
      " [ 1.02190039e+00]\n",
      " [ 9.62478241e-01]\n",
      " [ 9.68452507e-01]\n",
      " [ 9.25448859e-01]\n",
      " [ 8.42111768e-01]\n",
      " [ 8.65834077e-01]\n",
      " [ 9.91952875e-01]\n",
      " [ 8.93742155e-01]\n",
      " [ 8.17413421e-01]\n",
      " [ 9.86742253e-01]\n",
      " [ 1.04941998e+00]\n",
      " [ 8.07144457e-01]\n",
      " [ 8.91723287e-01]\n",
      " [ 9.82676583e-01]\n",
      " [ 1.06600742e+00]\n",
      " [ 9.11307601e-01]\n",
      " [ 1.12803576e+00]\n",
      " [ 9.58403864e-01]\n",
      " [ 8.86231427e-01]\n",
      " [ 9.75306789e-01]\n",
      " [ 1.04724480e+00]\n",
      " [ 9.31669463e-01]\n",
      " [ 1.04328470e+00]\n",
      " [ 1.22560873e+00]\n",
      " [ 1.08971834e+00]\n",
      " [ 9.41061064e-01]\n",
      " [ 1.03373186e+00]\n",
      " [ 8.83190078e-01]\n",
      " [ 9.75095138e-01]\n",
      " [ 1.05218043e+00]\n",
      " [ 1.10345402e+00]\n",
      " [ 1.04831977e+00]\n",
      " [ 9.53203755e-01]\n",
      " [ 9.81897978e-01]\n",
      " [ 1.09713540e+00]\n",
      " [ 9.63249958e-01]\n",
      " [ 1.11083175e+00]\n",
      " [ 8.78384441e-01]\n",
      " [ 1.04867234e+00]\n",
      " [ 9.22535047e-01]\n",
      " [ 1.06016525e+00]\n",
      " [ 9.22904609e-01]\n",
      " [ 9.27347750e-01]\n",
      " [ 1.03111582e+00]\n",
      " [ 1.07242014e+00]\n",
      " [ 1.07722878e+00]\n",
      " [ 9.23740276e-01]\n",
      " [ 9.13189360e-01]\n",
      " [ 1.02977844e+00]\n",
      " [ 1.05078908e+00]\n",
      " [ 1.19087806e+00]\n",
      " [ 9.72537801e-01]\n",
      " [ 7.73176558e-01]\n",
      " [ 1.06692767e+00]\n",
      " [ 1.00824651e+00]\n",
      " [ 1.05092788e+00]\n",
      " [ 1.05650936e+00]\n",
      " [ 8.82683796e-01]\n",
      " [ 1.01338810e+00]\n",
      " [ 8.93327393e-01]\n",
      " [ 8.37495417e-01]\n",
      " [ 1.04663421e+00]\n",
      " [ 9.81755295e-01]\n",
      " [ 7.96175727e-01]\n",
      " [ 9.65053816e-01]\n",
      " [ 1.02606202e+00]\n",
      " [ 6.82897673e-01]\n",
      " [ 9.87944156e-01]\n",
      " [ 9.30300883e-01]\n",
      " [ 9.78106626e-01]\n",
      " [ 1.03242627e+00]\n",
      " [ 1.14956224e+00]\n",
      " [ 1.08786611e+00]\n",
      " [ 9.80343691e-01]\n",
      " [ 9.98513892e-01]\n",
      " [ 1.03585147e+00]\n",
      " [ 9.77762196e-01]\n",
      " [ 7.33766601e-01]\n",
      " [ 8.80269266e-01]\n",
      " [ 9.73265472e-01]\n",
      " [ 8.75896860e-01]\n",
      " [ 9.64983254e-01]\n",
      " [ 9.83593462e-01]\n",
      " [ 9.27463336e-01]\n",
      " [ 9.54990362e-01]\n",
      " [ 1.10584450e+00]\n",
      " [ 1.01533117e+00]\n",
      " [ 1.15843426e+00]\n",
      " [ 1.00359259e+00]\n",
      " [ 1.05212797e+00]\n",
      " [ 9.36007199e-01]\n",
      " [ 9.22382314e-01]\n",
      " [ 9.55814672e-01]\n",
      " [ 7.35862424e-01]\n",
      " [ 1.22969823e+00]\n",
      " [ 7.72832699e-01]\n",
      " [ 1.00932746e+00]\n",
      " [ 9.78860429e-01]\n",
      " [ 8.98518066e-01]\n",
      " [ 1.23989698e-01]\n",
      " [ 3.25502872e-02]\n",
      " [-9.25951817e-02]\n",
      " [ 1.62823856e-03]\n",
      " [-1.63731069e-02]\n",
      " [ 1.51422436e-01]\n",
      " [-7.47265394e-02]\n",
      " [ 4.29658299e-02]\n",
      " [-5.42022149e-02]\n",
      " [-5.06922219e-03]\n",
      " [-1.05057211e-01]\n",
      " [-6.02541788e-02]\n",
      " [ 5.77551376e-02]\n",
      " [-8.28755127e-02]\n",
      " [ 2.33957135e-02]\n",
      " [-1.69500468e-02]\n",
      " [ 1.71954832e-01]\n",
      " [ 7.15753765e-03]\n",
      " [ 7.55087598e-02]\n",
      " [-3.35113857e-02]\n",
      " [ 1.36208538e-01]\n",
      " [ 2.42892066e-01]\n",
      " [ 1.94679194e-01]\n",
      " [ 7.12031530e-02]\n",
      " [ 2.03562008e-01]\n",
      " [-2.41289158e-01]\n",
      " [-6.94266941e-02]\n",
      " [ 6.02556851e-02]\n",
      " [ 4.87655920e-02]\n",
      " [ 2.16014037e-01]\n",
      " [ 4.33912091e-02]\n",
      " [ 8.20316865e-02]\n",
      " [ 2.13472970e-01]\n",
      " [ 1.27330066e-02]\n",
      " [-8.28380544e-02]\n",
      " [ 7.49528893e-02]\n",
      " [ 4.10431016e-02]\n",
      " [-1.29797053e-01]\n",
      " [ 8.22787539e-03]\n",
      " [ 1.40549960e-02]\n",
      " [ 2.33179140e-02]\n",
      " [ 6.02474448e-02]\n",
      " [ 3.05100780e-01]\n",
      " [-4.78743396e-03]\n",
      " [ 2.94852802e-02]\n",
      " [ 4.12376820e-02]\n",
      " [-7.09406701e-02]\n",
      " [ 5.47302652e-02]\n",
      " [-3.19115021e-01]\n",
      " [ 2.87672389e-02]\n",
      " [ 9.59117293e-02]\n",
      " [ 3.68389856e-03]\n",
      " [ 9.98176972e-02]\n",
      " [-5.33030734e-04]\n",
      " [ 1.18885160e-02]\n",
      " [-1.11141462e-01]\n",
      " [-5.57538426e-02]\n",
      " [-4.39530278e-03]\n",
      " [ 1.23577732e-01]\n",
      " [ 2.65039656e-01]\n",
      " [ 8.18504070e-02]\n",
      " [ 2.43633683e-01]\n",
      " [-6.45729126e-02]\n",
      " [-3.65882508e-03]\n",
      " [-4.09578537e-02]\n",
      " [-3.36415130e-02]\n",
      " [ 2.81914633e-02]\n",
      " [-9.05914946e-02]\n",
      " [ 1.54707384e-02]\n",
      " [ 1.05474125e-01]\n",
      " [ 1.65606400e-01]\n",
      " [-1.28894751e-01]\n",
      " [-2.61768542e-02]\n",
      " [ 5.73248270e-02]\n",
      " [-9.66697078e-02]\n",
      " [-8.67716790e-02]\n",
      " [ 7.80626055e-02]\n",
      " [ 8.67599420e-02]\n",
      " [-9.56477212e-02]\n",
      " [-5.25655633e-02]\n",
      " [-1.80603038e-01]\n",
      " [ 2.08633001e-01]\n",
      " [-1.53213041e-01]\n",
      " [-2.01485821e-01]\n",
      " [-3.79871839e-02]\n",
      " [ 5.81438978e-02]\n",
      " [-6.72995990e-03]\n",
      " [-3.97885287e-02]\n",
      " [ 7.47762453e-02]\n",
      " [-1.39801564e-01]\n",
      " [ 1.49589074e-01]\n",
      " [-8.02116760e-02]\n",
      " [ 1.15535452e-01]\n",
      " [-2.02281695e-02]\n",
      " [ 2.42985572e-01]\n",
      " [ 6.41919015e-02]\n",
      " [ 3.02028246e-01]\n",
      " [ 8.63721326e-02]\n",
      " [ 2.10170322e-01]\n",
      " [ 4.12759467e-02]\n",
      " [-1.12688693e-01]\n",
      " [ 5.15918214e-02]\n",
      " [-2.17864538e-03]\n",
      " [ 2.33481378e-02]\n",
      " [-3.49970230e-03]\n",
      " [ 7.66361480e-02]\n",
      " [ 5.72179156e-02]\n",
      " [ 7.52529947e-04]\n",
      " [-6.23120932e-02]\n",
      " [ 9.93257630e-02]\n",
      " [-1.31734733e-01]\n",
      " [ 1.91943712e-01]\n",
      " [-6.60858036e-02]\n",
      " [ 7.46737078e-02]\n",
      " [-7.78857233e-02]\n",
      " [ 1.60098271e-01]\n",
      " [ 3.37330062e-03]\n",
      " [-2.14368168e-02]\n",
      " [-7.57770997e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(a) Implement Logistic Regression via Gradient Descent. (5 points)\n",
    "#Now, without using any high-level machine learning libraries, implement logistic regression. Here, you’ll be using batch gradient descent, and will only need one logistic output unit. (Think about why we only need one if we’re classifying two classes?) The most points will be given for clean, well-documented code.\n",
    "def gradient_descent(X, y, lr=0.05, epoch=300):\n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    X -> feature -> m * d\n",
    "    y -> label -> m\n",
    "    lr -> learning rate\n",
    "    epoch -> epoch\n",
    "    \n",
    "    weights <-\n",
    "    mse     <-\n",
    "    '''\n",
    "    \n",
    "    weight = np.zeros((projected.shape[1], 1))\n",
    "    N = len(X) # number of samples\n",
    "    log = []\n",
    "    #log, mse = [], [] # lists to store learning process\n",
    "    # M * (d+1)--> X with last be bias term (feature)\n",
    "    # M * 1    --> y --> lable\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        errorSum = np.zeros((X.shape[1], 1))\n",
    "        #biasIncludedX = np.append(X, np.ones((X.shape[0], 1)), 1)\n",
    "        calculatedTarget = X@weight\n",
    "        #print(calculatedTarget, y)\n",
    "        diffs = y - calculatedTarget\n",
    "        #print(diffs.shape, y.shape, calculatedTarget.shape)\n",
    "        for i, diff in enumerate(diffs):\n",
    "            #print(diff.shape, errorSum.shape, X[i].shape)\n",
    "            #print(diff[0])\n",
    "            errorSum += diff[0] * X[i].reshape((-1, 1))\n",
    "        weight += errorSum * lr * (2/N)\n",
    "        log.append(sum(diffs**2)[0])\n",
    "\n",
    "    return weight, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newTrainingMiniVan = train['Minivan']\n",
    "#newTrainingConvertable = train['Convertible']\n",
    "y = []\n",
    "X = []\n",
    "for i in range(len(memo)):\n",
    "    if memo[i][0] == 'Convertible':\n",
    "        y.append(0)\n",
    "        X.append(projected[i])\n",
    "    elif memo[i][0] == 'Minivan':\n",
    "        y.append(1)\n",
    "        X.append(projected[i])\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(1, len(y)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 200)\n",
      "(237, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118.0, 117.95204991025547, 117.9041295251166, 117.85623882400905, 117.80837778637338, 117.76054639166554, 117.712744619356, 117.66497244893043, 117.61722985988915, 117.56951683174813, 117.52183334403742, 117.47417937630263, 117.42655490810381, 117.37895991901632, 117.33139438862993, 117.2838582965497, 117.23635162239532, 117.18887434580154, 117.14142644641748, 117.09400790390765, 117.04661869795116, 116.9992588082418, 116.95192821448835, 116.90462689641403, 116.8573548337573, 116.81011200627113, 116.7628983937231, 116.71571397589584, 116.66855873258662, 116.62143264360728, 116.57433568878429, 116.5272678479591, 116.48022910098766, 116.43321942774074, 116.3862388081036, 116.33928722197616, 116.2923646492733, 116.24547106992397, 116.19860646387197, 116.151770811076, 116.10496409150906, 116.0581862851587, 116.01143737202716, 115.96471733213139, 115.91802614550262, 115.87136379218653, 115.82473025224371, 115.77812550574913, 115.73154953279189, 115.68500231347629, 115.63848382792054, 115.59199405625746, 115.54553297863451, 115.49910057521345, 115.45269682617047, 115.40632171169628, 115.35997521199589, 115.31365730728888, 115.26736797780906, 115.22110720380489, 115.1748749655387, 115.12867124328777, 115.08249601734342, 115.0363492680113, 114.99023097561165, 114.94414112047866, 114.89807968296107, 114.85204664342197, 114.80604198223847, 114.76006567980211, 114.71411771651908, 114.66819807280908, 114.62230672910653, 114.57644366586024, 114.53060886353276, 114.48480230260125, 114.43902396355665, 114.393273826905, 114.34755187316506, 114.30185808287136, 114.25619243657151, 114.21055491482758, 114.16494549821574, 114.11936416732681, 114.07381090276465, 114.02828568514819, 113.98278849510999, 113.93731931329705, 113.89187812037001, 113.84646489700394, 113.80107962388767, 113.7557222817243, 113.71039285123112, 113.66509131313889, 113.61981764819278, 113.57457183715206, 113.52935386078975, 113.48416369989286, 113.43900133526266, 113.39386674771391, 113.3487599180758, 113.30368082719124, 113.25862945591692, 113.21360578512375, 113.16860979569626, 113.12364146853335, 113.07870078454702, 113.0337877246638, 112.98890226982411, 112.94404440098188, 112.89921409910491, 112.85441134517517, 112.80963612018824, 112.76488840515334, 112.72016818109374, 112.67547542904663, 112.63081013006249, 112.58617226520619, 112.54156181555588, 112.49697876220365, 112.4524230862553, 112.40789476883062, 112.36339379106259, 112.31892013409845, 112.27447377909881, 112.23005470723807, 112.18566289970424, 112.14129833769918, 112.09696100243832, 112.05265087515053, 112.00836793707886, 111.96411216947921, 111.91988355362197, 111.87568207079048, 111.83150770228191, 111.78736042940706, 111.74324023349038, 111.69914709586963, 111.65508099789633, 111.61104192093546, 111.56702984636574, 111.52304475557904, 111.4790866299812, 111.43515545099119, 111.39125120004161, 111.34737385857873, 111.30352340806209, 111.25969982996456, 111.21590310577288, 111.17213321698695, 111.12839014512019, 111.08467387169935, 111.04098437826487, 110.9973216463702, 110.95368565758257, 110.91007639348221, 110.86649383566326, 110.8229379657326, 110.7794087653109, 110.73590621603225, 110.69243029954356, 110.64898099750566, 110.60555829159236, 110.56216216349073, 110.5187925949015, 110.47544956753833, 110.43213306312812, 110.38884306341158, 110.34557955014209, 110.30234250508623, 110.25913191002454, 110.2159477467501, 110.17278999706947, 110.1296586428024, 110.08655366578171, 110.04347504785358, 110.00042277087749, 109.95739681672568, 109.91439716728375, 109.87142380445076, 109.82847671013828, 109.78555586627185, 109.74266125478921, 109.69979285764181, 109.65695065679394, 109.61413463422315, 109.57134477192008, 109.52858105188828, 109.48584345614442, 109.4431319667181, 109.4004465656524, 109.35778723500296, 109.31515395683876, 109.27254671324141, 109.22996548630604, 109.18741025814022, 109.14488101086506, 109.10237772661415, 109.05990038753431, 109.01744897578531, 108.97502347354002, 108.93262386298362, 108.89025012631497, 108.84790224574539, 108.80558020349912, 108.7632839818137, 108.7210135629391, 108.6787689291381, 108.63655006268698, 108.59435694587437, 108.55218956100177, 108.5100478903836, 108.46793191634711, 108.42584162123237, 108.38377698739252, 108.34173799719285, 108.29972463301206, 108.25773687724143, 108.21577471228481, 108.17383812055913, 108.13192708449391, 108.09004158653148, 108.0481816091267, 108.00634713474759, 107.96453814587431, 107.9227546250002, 107.88099655463101, 107.83926391728524, 107.79755669549436, 107.75587487180205, 107.7142184287648, 107.67258734895213, 107.63098161494554, 107.58940120933953, 107.54784611474133, 107.5063163137705, 107.46481178905918, 107.4233325232528, 107.38187849900825, 107.34044969899588, 107.29904610589803, 107.25766770241006, 107.21631447123956, 107.1749863951069, 107.1336834567447, 107.0924056388984, 107.05115292432545, 107.0099252957964, 106.96872273609408, 106.92754522801336, 106.88639275436248, 106.84526529796103, 106.8041628416421, 106.76308536825054, 106.7220328606439, 106.68100530169214, 106.64000267427728, 106.59902496129469, 106.55807214565078, 106.51714421026573, 106.47624113807092, 106.43536291201089, 106.3945095150422, 106.35368093013378, 106.31287714026703, 106.27209812843543, 106.23134387764497, 106.19061437091409, 106.1499095912733, 106.10922952176529, 106.0685741454453, 106.02794344538096, 105.98733740465168, 105.9467560063496, 105.90619923357883, 105.86566706945584, 105.82515949710931, 105.78467649967997, 105.74421806032116, 105.70378416219793, 105.66337478848808, 105.62298992238098, 105.58262954707855, 105.54229364579493, 105.50198220175605, 105.46169519820062, 105.42143261837877, 105.38119444555313, 105.34098066299859, 105.30079125400171, 105.26062620186156, 105.220485489889, 105.18036910140734, 105.14027701975155, 105.10020922826908, 105.06016571031914, 105.02014644927297, 104.98015142851382, 104.94018063143757, 104.90023404145114]\n"
     ]
    }
   ],
   "source": [
    "w, l = gradient_descent(X, y)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationConvertable = test['Convertible']\n",
    "validationMinivan     = test['Minivan']\n",
    "\n",
    "validationPCAed = []\n",
    "validationY = []\n",
    "for i in range(len(validationConvertable)):\n",
    "    validationPCAed.append((np.matmul(validationConvertable[i].reshape(1, 60000) - mean_image, top_eigen_vectors)/top_sqrt_eigen_values)[0])\n",
    "    validationY.append(0)\n",
    "for i in range(len(validationMinivan)):\n",
    "    validationPCAed.append((np.matmul(validationMinivan[i].reshape(1, 60000) - mean_image, top_eigen_vectors)/top_sqrt_eigen_values)[0])\n",
    "    validationY.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validationPCAed))\n",
    "validationPCAed = np.array(validationPCAed)\n",
    "print(validationPCAed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed = np.append(validationPCAed, np.ones((validationPCAed.shape[0], 1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
