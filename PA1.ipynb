{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "from os import listdir\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./aligned/\"):\n",
    "    \"\"\" Load all PNG images stored in your data directory into a list of NumPy\n",
    "        arrays.\n",
    "\n",
    "    Args:\n",
    "    data_dir: The relative directory path to the CompCar image directory.\n",
    "    Returns:\n",
    "        images: A dictionary with keys as car types and a list containing images associated with each key.\n",
    "        cnt: A dictionary that stores the # of images in each car type\n",
    "    \"\"\"\n",
    "    images = defaultdict(list)\n",
    "\n",
    "    # Get the list of car type directory:\n",
    "    for e in listdir(data_dir):\n",
    "        # excluding any non-directory files\n",
    "        if not os.path.isdir(os.path.join(data_dir, e)):\n",
    "            continue\n",
    "        # Get the list of image file names\n",
    "        all_files = listdir(os.path.join(data_dir, e))\n",
    "\n",
    "        for file in all_files:\n",
    "            # Load only image files as PIL images and convert to NumPy arrays\n",
    "            if '.jpg' in file:\n",
    "                img = Image.open(os.path.join(data_dir, e, file))\n",
    "                images[e].append(np.array(img))\n",
    "\n",
    "    print(\"Car types: {} \\n\".format(list(images.keys())))\n",
    "\n",
    "    cnt = defaultdict(int)\n",
    "    for e in images.keys():\n",
    "        print(\"{}: {} # of images\".format(e, len(images[e])))\n",
    "        cnt[e] = len(images[e])\n",
    "    return images, cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in all the img from all set and return a list of sets of mutually exclusive images and its labels.\n",
    "def k_fold(imgs, k):\n",
    "    res = []\n",
    "    for _ in range(k):\n",
    "        res.append(defaultdict(list))\n",
    "    for key in imgs.keys():\n",
    "        for i, entry in enumerate(imgs[key]):\n",
    "            res[i%k][key].append(entry)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, n_components):\n",
    "\n",
    "    \"\"\"Args:\n",
    "        X: has shape Mxd where M is the number of images and d is the dimension of each image\n",
    "        n_components: The number of components you want to project your image onto. \n",
    "    \n",
    "    Returns:\n",
    "        projected: projected data of shape M x n_components\n",
    "        mean_image: mean of all images\n",
    "        top_sqrt_eigen_values: singular values\n",
    "        top_eigen_vectors: eigenvectors \n",
    "    \"\"\"\n",
    "    mean_image = np.average(X, axis = 0)\n",
    "\n",
    "    msd = X - mean_image # M x d\n",
    "\n",
    "    smart_cov_matrix = np.matmul(msd, msd.T)\n",
    "    eigen_values, smart_eigen_vectors = np.linalg.eig(smart_cov_matrix)\n",
    "\n",
    "    idx = eigen_values.argsort()[::-1]   \n",
    "    eigen_values = eigen_values[idx]\n",
    "    smart_eigen_vectors = smart_eigen_vectors[:,idx]\n",
    "\n",
    "    eigen_vectors = (np.matmul(msd.T, smart_eigen_vectors)).T # M x d\n",
    "\n",
    "    row_norm = np.sum(np.abs(eigen_vectors)**2,axis=-1)**(1./2) # M\n",
    "\n",
    "    normalized_eigen_vectors = eigen_vectors/(row_norm.reshape(-1, 1)) # M x d\n",
    "\n",
    "    top_eigen_vectors = normalized_eigen_vectors[:n_components].T\n",
    "    top_sqrt_eigen_values = np.sqrt(eigen_values[:n_components])\n",
    "\n",
    "    projected = np.matmul(msd, top_eigen_vectors)/top_sqrt_eigen_values\n",
    "\n",
    "    return projected, mean_image, top_sqrt_eigen_values, top_eigen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car types: ['Convertible', 'Pickup', 'Minivan', 'Sedan'] \n",
      "\n",
      "Convertible: 149 # of images\n",
      "Pickup: 150 # of images\n",
      "Minivan: 148 # of images\n",
      "Sedan: 150 # of images\n"
     ]
    }
   ],
   "source": [
    "img, cnt = load_data()\n",
    "folds = k_fold(img, 10)\n",
    "test, validation = folds[0], folds[1]\n",
    "train = defaultdict(list)\n",
    "for trainLoaderIter in range(2, 10):\n",
    "    for key in folds[trainLoaderIter].keys():\n",
    "        train[key].extend(folds[trainLoaderIter][key])\n",
    "totalTrainingAmount = 0\n",
    "for key in train.keys():\n",
    "    totalTrainingAmount += len(train[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477\n"
     ]
    }
   ],
   "source": [
    "print(totalTrainingAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newTrainingConvertable = train['Convertible']\n",
    "X = []\n",
    "y= []\n",
    "\n",
    "for i in range(len(train['Convertible'])):\n",
    "    X.append(train['Convertible'][i].reshape((-1)))\n",
    "    y.append(0)\n",
    "for i in range(len(train['Minivan'])):\n",
    "    X.append(train['Minivan'][i].reshape((-1)))\n",
    "    y.append(1)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(1, len(y)).T\n",
    "#print(X.shape, y.shape)\n",
    "#from sklearn.decomposition import PCA as skPCA\n",
    "\n",
    "#pca = skPCA(n_components=)\n",
    "#X = pca.fit_transform(X)\n",
    "#print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected, mean_image, top_sqrt_eigen_values, top_eigen_vectors = PCA(X, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_regression:\n",
    "    def __init__(self, dimension, lr):\n",
    "        self.lr = lr\n",
    "        self.w = np.zeros(dimension)\n",
    "        \n",
    "    def sigmoid(self, X):\n",
    "        return 1.0 / (1.0 + np.exp(-X))\n",
    "    \n",
    "    def caculateGradient(self, X, yTrue):\n",
    "        expected = self.w @ X.T\n",
    "        diffs = yTrue-expected.reshape((-1,1))\n",
    "        gradient = (X*diffs).sum(axis=0)\n",
    "        return gradient*(1/len(X))\n",
    "        \n",
    "    def updateWeight(self, X, yTrue):\n",
    "        self.w = self.w + self.lr * self.caculateGradient(X, yTrue)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X@self.w.T)\n",
    "    \n",
    "    def score(self, X, yTrue):\n",
    "        yCalculated = self.predict(X)\n",
    "        correct = 0\n",
    "        for i in range(len(X)):\n",
    "            print(yCalculated[i], yTrue[i])\n",
    "            if yCalculated[i] == yTrue[i]:\n",
    "                correct += 1\n",
    "        return correct / len(yCalculated)\n",
    "    \n",
    "    def logLikelihood(self, X, yTrue):\n",
    "        expected = self.sigmoid(self.w @ X.T)\n",
    "        LLs = yTrue*np.log(expected).reshape((-1,1)) + (1-yTrue)*np.log(1-expected).reshape((-1,1))\n",
    "        return LLs.sum(axis=0)\n",
    "    \n",
    "    def fit(self, X, y, epoch):\n",
    "        log = []\n",
    "        for _ in range(epoch):\n",
    "            self.updateWeight(X, y)\n",
    "            log.append(self.logLikelihood(X, y))\n",
    "        return log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = Logistic_regression(projected.shape[1], 0.02)\n",
    "Loss = LR.fit(projected, y, 55000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log likelihood')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Loss)\n",
    "plt.title(\"Log likelihood vs Steps (Training)\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Log likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(a) Implement Logistic Regression via Gradient Descent. (5 points)\n",
    "#Now, without using any high-level machine learning libraries, implement logistic regression. Here, you’ll be using batch gradient descent, and will only need one logistic output unit. (Think about why we only need one if we’re classifying two classes?) The most points will be given for clean, well-documented code.\n",
    "def gradient_descent(X, y, lr=0.05, epoch=300):\n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    X -> feature -> m * d\n",
    "    y -> label -> m\n",
    "    lr -> learning rate\n",
    "    epoch -> epoch\n",
    "    \n",
    "    weights <-\n",
    "    mse     <-\n",
    "    '''\n",
    "    \n",
    "    weight = np.zeros((X.shape[1], 1))\n",
    "    N = len(X) # number of samples\n",
    "    log = []\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        errorSum = np.zeros((X.shape[1], 1))\n",
    "        #biasIncludedX = np.append(X, np.ones((X.shape[0], 1)), 1)\n",
    "        calculatedTarget = X@weight\n",
    "        #print(calculatedTarget, y)\n",
    "        diffs = y - calculatedTarget\n",
    "        #print(diffs.shape, y.shape, calculatedTarget.shape)\n",
    "        for i, diff in enumerate(diffs):\n",
    "            #print(diff.shape, errorSum.shape, X[i].shape)\n",
    "            #print(diff[0])\n",
    "            errorSum += diff[0] * X[i].reshape((-1, 1))\n",
    "        weight += errorSum * lr * (2/N)\n",
    "        #print(weight)\n",
    "        log.append(sum(diffs**2)[0])\n",
    "\n",
    "    return weight, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, l = gradient_descent(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(X, mean_image, n_components):\n",
    "    msd = X - mean_image # M x d\n",
    "\n",
    "    smart_cov_matrix = np.matmul(msd, msd.T)\n",
    "    eigen_values, smart_eigen_vectors = np.linalg.eig(smart_cov_matrix)\n",
    "\n",
    "    idx = eigen_values.argsort()[::-1]   \n",
    "    eigen_values = eigen_values[idx]\n",
    "    smart_eigen_vectors = smart_eigen_vectors[:,idx]\n",
    "\n",
    "    eigen_vectors = (np.matmul(msd.T, smart_eigen_vectors)).T # M x d\n",
    "\n",
    "    row_norm = np.sum(np.abs(eigen_vectors)**2,axis=-1)**(1./2) # M\n",
    "\n",
    "    normalized_eigen_vectors = eigen_vectors/(row_norm.reshape(-1, 1)) # M x d\n",
    "\n",
    "    top_eigen_vectors = normalized_eigen_vectors[:n_components].T\n",
    "    top_sqrt_eigen_values = np.sqrt(eigen_values[:n_components])\n",
    "\n",
    "    projected = np.matmul(msd, top_eigen_vectors)/top_sqrt_eigen_values\n",
    "\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(a) Implement Logistic Regression via Gradient Descent. (5 points)\n",
    "#Now, without using any high-level machine learning libraries, implement logistic regression. Here, you’ll be using batch gradient descent, and will only need one logistic output unit. (Think about why we only need one if we’re classifying two classes?) The most points will be given for clean, well-documented code.\n",
    "def gradient_descent(X, y, lr=0.05, epoch=300):\n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    X -> feature -> m * d\n",
    "    y -> label -> m\n",
    "    lr -> learning rate\n",
    "    epoch -> epoch\n",
    "    \n",
    "    weights <-\n",
    "    mse     <-\n",
    "    '''\n",
    "    \n",
    "    weight = np.zeros((projected.shape[1], 1))\n",
    "    N = len(X) # number of samples\n",
    "    log = []\n",
    "    #log, mse = [], [] # lists to store learning process\n",
    "    # M * (d+1)--> X with last be bias term (feature)\n",
    "    # M * 1    --> y --> lable\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        errorSum = np.zeros((X.shape[1], 1))\n",
    "        #biasIncludedX = np.append(X, np.ones((X.shape[0], 1)), 1)\n",
    "        calculatedTarget = X@weight\n",
    "        #print(calculatedTarget, y)\n",
    "        diffs = y - calculatedTarget\n",
    "        #print(diffs.shape, y.shape, calculatedTarget.shape)\n",
    "        for i, diff in enumerate(diffs):\n",
    "            #print(diff.shape, errorSum.shape, X[i].shape)\n",
    "            #print(diff[0])\n",
    "            errorSum += diff[0] * X[i].reshape((-1, 1))\n",
    "        weight += errorSum * lr * (2/N)\n",
    "        log.append(sum(diffs**2)[0])\n",
    "\n",
    "    return weight, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newTrainingMiniVan = train['Minivan']\n",
    "#newTrainingConvertable = train['Convertible']\n",
    "y = []\n",
    "X = []\n",
    "for i in range(len(memo)):\n",
    "    if memo[i][0] == 'Convertible':\n",
    "        y.append(0)\n",
    "        X.append(projected[i])\n",
    "    elif memo[i][0] == 'Minivan':\n",
    "        y.append(1)\n",
    "        X.append(projected[i])\n",
    "X = np.array(X)\n",
    "y = np.array(y).reshape(1, len(y)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, l = gradient_descent(X, y)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationConvertable = test['Convertible']\n",
    "validationMinivan     = test['Minivan']\n",
    "\n",
    "validationPCAed = []\n",
    "validationY = []\n",
    "for i in range(len(validationConvertable)):\n",
    "    validationPCAed.append((np.matmul(validationConvertable[i].reshape(1, 60000) - mean_image, top_eigen_vectors)/top_sqrt_eigen_values)[0])\n",
    "    validationY.append(0)\n",
    "for i in range(len(validationMinivan)):\n",
    "    validationPCAed.append((np.matmul(validationMinivan[i].reshape(1, 60000) - mean_image, top_eigen_vectors)/top_sqrt_eigen_values)[0])\n",
    "    validationY.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validationPCAed))\n",
    "validationPCAed = np.array(validationPCAed)\n",
    "print(validationPCAed.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed = np.append(validationPCAed, np.ones((validationPCAed.shape[0], 1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationPCAed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
